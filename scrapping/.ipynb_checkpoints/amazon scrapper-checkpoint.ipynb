{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea7d6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "656342ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.com/s?k=jacket+for+men&ref=nb_sb_noss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0737567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': 2})\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7480838e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "string = 'Sorry, we just need to make sure you\\'re not a robot. For best results, please make sure your browser is accepting cookies'\n",
    "string in soup.find('body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4d3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page -  1\n",
      "scraping page -  2\n",
      "scraping page -  3\n",
      "scraping page -  4\n",
      "scraping page -  5\n",
      "scraping page -  6\n",
      "scraping page -  7\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "product_links = pd.DataFrame(columns=['product', 'link'])\n",
    "i = 0\n",
    "\n",
    "url = 'https://www.amazon.com/s?k=jacket+for+men&ref=nb_sb_noss'\n",
    "\n",
    "for page in range(1, 1000):\n",
    "\n",
    "    print(\"scraping page - \", page)\n",
    "    \n",
    "    r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': 3})\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    # stop if next page button is disabled\n",
    "    if soup.find('li', {'class': 'a-disabled a-last'}):\n",
    "        break\n",
    "    else:\n",
    "        # go to next page\n",
    "        # find element of next page\n",
    "        next_links = soup.find_all('li', {'class':'a-last'})\n",
    "        for link in next_links:\n",
    "            url = 'https://amazon.com' + str(link.find('a')['href'])\n",
    "    \n",
    "    products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "\n",
    "    for product in products:\n",
    "        item = product.find('a', {'class':'a-link-normal s-underline-text s-underline-link-text a-text-normal'})\n",
    "        if item == None:\n",
    "            item = product.find('a', {'class':'a-link-normal a-text-normal'})\n",
    "        title = item.text.strip()\n",
    "        link = item['href']\n",
    "        product_links.loc[i] = [title, link]\n",
    "        i = i+1\n",
    "    if not page == 1:\n",
    "        soup = soup.find_all('li', {'class':'a-normal'})\n",
    "\n",
    "print('done')\n",
    "product_links.to_csv('scraped_product_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ddc227a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22 % product pages scraped\n",
      "Not enough reviews - adding empty entries\n",
      " 22 % product pages scraped\n",
      "Not enough reviews - adding empty entries\n",
      " 22 % product pages scraped\n",
      "Not enough reviews - adding empty entries\n",
      " 23 % product pages scraped\n",
      "Not enough reviews - adding empty entries\n",
      " 23 % product pages scraped\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-2d487be966fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://amazon.com'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murl_base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://localhost:8000/render.html'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wait'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "products = pd.read_csv('products_complete.csv')\n",
    "\n",
    "#products['features'] = ''\n",
    "#products['description'] = ''\n",
    "#products['review_pages'] = ''\n",
    "\n",
    "for i in range(102, len(products)):\n",
    "    \n",
    "    print(\"\", round((100 * i) / len(products)), \"% product pages scraped\")\n",
    "    \n",
    "    url_base = products['link'].iloc[i]\n",
    "    url = 'https://amazon.com' + url_base\n",
    "\n",
    "    r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': random.randint(2,20)})\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        if str(r) == \"<Response [503]>\" or string in soup.find('body').text:\n",
    "            print('#####amazon is blocking you######')\n",
    "            print('no of pages scraped - ',i )\n",
    "            break\n",
    "    except:\n",
    "        print('#####amazon is blocking you######')\n",
    "        print('no of pages scraped - ',i )\n",
    "        break\n",
    "\n",
    "    product_features = ''\n",
    "    product_description = ''\n",
    "    review_page_link = ''\n",
    "    \n",
    "    review_item = soup.find({'a'}, {'data-hook':\"see-all-reviews-link-foot\"})\n",
    "    \n",
    "    if review_item is None:          \n",
    "        products['features'][i] = product_features\n",
    "        products['description'][i] = product_description\n",
    "        products['review_pages'][i] = review_page_link\n",
    "        print('Not enough reviews - adding empty entries')\n",
    "        continue\n",
    "        \n",
    "    review_page_link = review_item['href']\n",
    "\n",
    "    feature_list_conatiner = soup.find({'div'}, {'id':\"feature-bullets\"})\n",
    "    feature_list = feature_list_conatiner.find_all({'span'}, {'class':\"a-list-item\"})\n",
    "    for feature in feature_list:\n",
    "        product_features = product_features + \" \" + feature.text.strip()\n",
    "\n",
    "    product_description_container = soup.find('div', \n",
    "                                              {'cel_widget_id':\n",
    "                                               \"dpx-aplus-3p-product-description_csm_instrumentation_wrapper\"})    \n",
    "    \n",
    "    if product_description_container == None:\n",
    "        product_description_container = soup.find('div', {'id':'productDescription'})\n",
    "\n",
    "    if product_description_container == None:\n",
    "        products['features'][i] = product_features\n",
    "        products['description'][i] = product_description\n",
    "        products['review_pages'][i] = review_page_link\n",
    "        continue\n",
    "    \n",
    "    lists = product_description_container.find_all({'span'}, {'class':\"a-list-item\"})\n",
    "    \n",
    "    for item in lists:\n",
    "        product_description = product_description + \" \" + item.text.strip()\n",
    "\n",
    "    paras = product_description_container.find_all('p')\n",
    "    for para in paras:\n",
    "        if '<img alt=' in para.text:\n",
    "            continue\n",
    "        product_description = product_description + \" \" + para.text.strip()\n",
    "    \n",
    "    products['features'][i] = product_features\n",
    "    products['description'][i] = product_description\n",
    "    products['review_pages'][i] = review_page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9130ef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!--\n",
       "        To discuss automated access to Amazon data please contact api-services-support@amazon.com.\n",
       "        For information about migrating to our APIs refer to our Marketplace APIs at https://developer.amazonservices.com/ref=rm_5_sv, or our Product Advertising API at https://affiliate-program.amazon.com/gp/advertising/api/detail/main.html/ref=rm_5_ac for advertising use cases.\n",
       "--><!DOCTYPE html>\n",
       "<html><head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"ie=edge\" http-equiv=\"x-ua-compatible\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
       "<title>Sorry! Something went wrong!</title>\n",
       "<style>\n",
       "  html, body {\n",
       "    padding: 0;\n",
       "    margin: 0\n",
       "  }\n",
       "\n",
       "  img {\n",
       "    border: 0\n",
       "  }\n",
       "\n",
       "  #a {\n",
       "    background: #232f3e;\n",
       "    padding: 11px 11px 11px 192px\n",
       "  }\n",
       "\n",
       "  #b {\n",
       "    position: absolute;\n",
       "    left: 22px;\n",
       "    top: 12px\n",
       "  }\n",
       "\n",
       "  #c {\n",
       "    position: relative;\n",
       "    max-width: 800px;\n",
       "    padding: 0 40px 0 0\n",
       "  }\n",
       "\n",
       "  #e, #f {\n",
       "    height: 35px;\n",
       "    border: 0;\n",
       "    font-size: 1em\n",
       "  }\n",
       "\n",
       "  #e {\n",
       "    width: 100%;\n",
       "    margin: 0;\n",
       "    padding: 0 10px;\n",
       "    border-radius: 4px 0 0 4px\n",
       "  }\n",
       "\n",
       "  #f {\n",
       "    cursor: pointer;\n",
       "    background: #febd69;\n",
       "    font-weight: bold;\n",
       "    border-radius: 0 4px 4px 0;\n",
       "    -webkit-appearance: none;\n",
       "    position: absolute;\n",
       "    top: 0;\n",
       "    right: 0;\n",
       "    padding: 0 12px\n",
       "  }\n",
       "\n",
       "  @media (max-width: 500px) {\n",
       "    #a {\n",
       "      padding: 55px 10px 10px\n",
       "    }\n",
       "\n",
       "    #b {\n",
       "      left: 6px\n",
       "    }\n",
       "  }\n",
       "\n",
       "  #g {\n",
       "    text-align: center;\n",
       "    margin: 30px 0\n",
       "  }\n",
       "\n",
       "  #g img {\n",
       "    max-width: 90%\n",
       "  }\n",
       "\n",
       "  #d {\n",
       "    display: none\n",
       "  }\n",
       "\n",
       "  #d[src] {\n",
       "    display: inline\n",
       "  }\n",
       "  </style>\n",
       "</head>\n",
       "<body>\n",
       "<a href=\"/ref=cs_503_logo\"><img alt=\"Amazon.com\" id=\"b\" src=\"https://images-na.ssl-images-amazon.com/images/G/01/error/logo._TTD_.png\"/></a>\n",
       "<form accept-charset=\"utf-8\" action=\"/s\" id=\"a\" method=\"GET\" role=\"search\">\n",
       "<div id=\"c\">\n",
       "<input id=\"e\" name=\"field-keywords\" placeholder=\"Search\"/>\n",
       "<input name=\"ref\" type=\"hidden\" value=\"cs_503_search\"/>\n",
       "<input id=\"f\" type=\"submit\" value=\"Go\"/>\n",
       "</div>\n",
       "</form>\n",
       "<div id=\"g\">\n",
       "<div><a href=\"/ref=cs_503_link\"><img alt=\"Sorry! Something went wrong on our end. Please go back and try again or go to Amazon's home page.\" src=\"https://images-na.ssl-images-amazon.com/images/G/01/error/500_503.png\"/></a>\n",
       "</div>\n",
       "<a href=\"/dogsofamazon/ref=cs_503_d\" rel=\"noopener noreferrer\" target=\"_blank\"><img alt=\"Dogs of Amazon\" id=\"d\" src=\"https://images-na.ssl-images-amazon.com/images/G/01/error/14._TTD_.jpg\"/></a>\n",
       "<script>document.getElementById(\"d\").src = \"https://images-na.ssl-images-amazon.com/images/G/01/error/\" + (Math.floor(Math.random() * 43) + 1) + \"._TTD_.jpg\";</script>\n",
       "</div>\n",
       "</body></html>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d6c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "935587f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv('products_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eec1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_title(item):\n",
    "    if item == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return item.text.strip().replace('\\n', '')\n",
    "    \n",
    "def clean_rating(item):\n",
    "    if item == None:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(item.text[:3])\n",
    "\n",
    "def clean_body(item):\n",
    "    if item == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return item.text.strip()\n",
    "df = pd.DataFrame(columns = ['product', 'review_title', 'review_rating', 'review_text'])\n",
    "\n",
    "i = 0\n",
    "products = pd.read_csv('products_complete.csv')\n",
    "\n",
    "for prd_idx in range(len(products)):\n",
    "    print('scraping reviews of product - ', prd_idx + 1)\n",
    "    url_base = products['review_pages'][prd_idx]\n",
    "    \n",
    "    if url_base == \"\":\n",
    "        continue\n",
    "    \n",
    "    for page in range(1,100):\n",
    "        print('scraping ', i, ' review page of product - ', prd_idx + 1)\n",
    "        url = 'https://amazon.com' + url_base + str(page)\n",
    "        r = requests.get('http://localhost:8051/render.html', {'url': url, 'wait': random.randint(2,20)})\n",
    "        \n",
    "        if str(r) == \"<Response [503]>\" or str(r) == \"<Response [200]>\":\n",
    "            print('#####amazon is blocking you######')\n",
    "            print('no of pages scraped - ',i )\n",
    "            break\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        #check if we have reached last page\n",
    "        if soup.find('li', {'class': 'a-disabled a-last'}):\n",
    "            break\n",
    "\n",
    "        reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "        for items in reviews:\n",
    "            product = soup.title.text.replace('Amazon.com: Customer reviews:', '').strip()\n",
    "            reviews_title= clean_title(items.find('a', {'data-hook': 'review-title'}))\n",
    "            review_rating= clean_rating(items.find('i', {'data-hook': 'review-star-rating'}))\n",
    "            reviews_text= clean_body(items.find('span', {'data-hook': 'review-body'}))\n",
    "            df.loc[i] = [product, reviews_title, review_rating, reviews_text]\n",
    "            i = i + 1\n",
    "\n",
    "print(\"Done scraping\")        \n",
    "df.to_csv('scraped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de8dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
