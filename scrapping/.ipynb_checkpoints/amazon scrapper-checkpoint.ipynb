{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7d6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656342ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.com/s?k=jacket+for+men&ref=nb_sb_noss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0737567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': 2})\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7480838e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "string = 'Sorry, we just need to make sure you\\'re not a robot. For best results, please make sure your browser is accepting cookies'\n",
    "string in soup.find('body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4d3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page -  1\n",
      "scraping page -  2\n",
      "scraping page -  3\n",
      "scraping page -  4\n",
      "scraping page -  5\n",
      "scraping page -  6\n",
      "scraping page -  7\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "product_links = pd.DataFrame(columns=['product', 'link'])\n",
    "i = 0\n",
    "\n",
    "url = 'https://www.amazon.com/s?k=jacket+for+men&ref=nb_sb_noss'\n",
    "\n",
    "for page in range(1, 1000):\n",
    "\n",
    "    print(\"scraping page - \", page)\n",
    "    \n",
    "    r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': 3})\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    # stop if next page button is disabled\n",
    "    if soup.find('li', {'class': 'a-disabled a-last'}):\n",
    "        break\n",
    "    else:\n",
    "        # go to next page\n",
    "        # find element of next page\n",
    "        next_links = soup.find_all('li', {'class':'a-last'})\n",
    "        for link in next_links:\n",
    "            url = 'https://amazon.com' + str(link.find('a')['href'])\n",
    "    \n",
    "    products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "\n",
    "    for product in products:\n",
    "        item = product.find('a', {'class':'a-link-normal s-underline-text s-underline-link-text a-text-normal'})\n",
    "        if item == None:\n",
    "            item = product.find('a', {'class':'a-link-normal a-text-normal'})\n",
    "        title = item.text.strip()\n",
    "        link = item['href']\n",
    "        product_links.loc[i] = [title, link]\n",
    "        i = i+1\n",
    "    if not page == 1:\n",
    "        soup = soup.find_all('li', {'class':'a-normal'})\n",
    "\n",
    "print('done')\n",
    "product_links.to_csv('scraped_product_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ddc227a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30 % product pages scraped\n",
      " 30 % product pages scraped\n",
      " 31 % product pages scraped\n",
      "#####amazon is blocking you######\n",
      "no of pages scraped -  110\n"
     ]
    }
   ],
   "source": [
    "products = pd.read_csv('products_complete.csv')\n",
    "\n",
    "#products['features'] = ''\n",
    "#products['description'] = ''\n",
    "#products['review_pages'] = ''\n",
    "\n",
    "for i in range(110, len(products)):\n",
    "    \n",
    "    print(\"\", round((100 * i) / len(products)), \"% product pages scraped\")\n",
    "    \n",
    "    url_base = products['link'].iloc[i]\n",
    "    url = 'https://amazon.com' + url_base\n",
    "\n",
    "    r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': random.randint(2,20)})\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        if str(r) == \"<Response [503]>\" or string in soup.find('body').text:\n",
    "            print('#####amazon is blocking you######')\n",
    "            print('no of pages scraped - ',i )\n",
    "            break\n",
    "    except:\n",
    "        print('#####amazon is blocking you######')\n",
    "        print('no of pages scraped - ',i )\n",
    "        break\n",
    "\n",
    "    product_features = ''\n",
    "    product_description = ''\n",
    "    review_page_link = ''\n",
    "    \n",
    "    review_item = soup.find({'a'}, {'data-hook':\"see-all-reviews-link-foot\"})\n",
    "    \n",
    "    if review_item is None:          \n",
    "        products['features'][i] = product_features\n",
    "        products['description'][i] = product_description\n",
    "        products['review_pages'][i] = review_page_link\n",
    "        print('Not enough reviews - adding empty entries')\n",
    "        continue\n",
    "        \n",
    "    review_page_link = review_item['href']\n",
    "\n",
    "    feature_list_conatiner = soup.find({'div'}, {'id':\"feature-bullets\"})\n",
    "    feature_list = feature_list_conatiner.find_all({'span'}, {'class':\"a-list-item\"})\n",
    "    for feature in feature_list:\n",
    "        product_features = product_features + \" \" + feature.text.strip()\n",
    "\n",
    "    product_description_container = soup.find('div', \n",
    "                                              {'cel_widget_id':\n",
    "                                               \"dpx-aplus-3p-product-description_csm_instrumentation_wrapper\"})    \n",
    "    \n",
    "    if product_description_container == None:\n",
    "        product_description_container = soup.find('div', {'id':'productDescription'})\n",
    "\n",
    "    if product_description_container == None:\n",
    "        products['features'][i] = product_features\n",
    "        products['description'][i] = product_description\n",
    "        products['review_pages'][i] = review_page_link\n",
    "        continue\n",
    "    \n",
    "    lists = product_description_container.find_all({'span'}, {'class':\"a-list-item\"})\n",
    "    \n",
    "    for item in lists:\n",
    "        product_description = product_description + \" \" + item.text.strip()\n",
    "\n",
    "    paras = product_description_container.find_all('p')\n",
    "    for para in paras:\n",
    "        if '<img alt=' in para.text:\n",
    "            continue\n",
    "        product_description = product_description + \" \" + para.text.strip()\n",
    "    \n",
    "    products['features'][i] = product_features\n",
    "    products['description'][i] = product_description\n",
    "    products['review_pages'][i] = review_page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9130ef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"error\": 504, \"type\": \"GlobalTimeoutError\", \"description\": \"Timeout exceeded rendering page\", \"info\": {\"remaining\": -0.013931035995483398, \"timeout\": 30}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6c0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935587f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.to_csv('products_complete.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31eec1c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping reviews of product -  15\n",
      "scraping reviews of product -  16\n",
      "scraping  1540  review page of product -  16\n",
      "scraping  1550  review page of product -  16\n",
      "scraping  1560  review page of product -  16\n",
      "scraping  1570  review page of product -  16\n",
      "scraping  1580  review page of product -  16\n",
      "scraping  1590  review page of product -  16\n",
      "scraping  1600  review page of product -  16\n",
      "scraping  1610  review page of product -  16\n",
      "scraping  1620  review page of product -  16\n",
      "scraping  1630  review page of product -  16\n",
      "scraping  1640  review page of product -  16\n",
      "scraping  1650  review page of product -  16\n",
      "scraping  1660  review page of product -  16\n",
      "scraping  1670  review page of product -  16\n",
      "scraping reviews of product -  17\n",
      "scraping  1680  review page of product -  17\n",
      "scraping  1690  review page of product -  17\n",
      "scraping  1700  review page of product -  17\n",
      "scraping  1710  review page of product -  17\n",
      "scraping  1720  review page of product -  17\n",
      "scraping  1730  review page of product -  17\n",
      "scraping  1740  review page of product -  17\n",
      "scraping  1750  review page of product -  17\n",
      "scraping  1760  review page of product -  17\n",
      "scraping  1770  review page of product -  17\n",
      "scraping  1780  review page of product -  17\n",
      "scraping  1790  review page of product -  17\n",
      "scraping  1800  review page of product -  17\n",
      "scraping  1810  review page of product -  17\n",
      "scraping reviews of product -  18\n",
      "scraping  1820  review page of product -  18\n",
      "scraping  1830  review page of product -  18\n",
      "scraping  1840  review page of product -  18\n",
      "scraping  1850  review page of product -  18\n",
      "scraping  1860  review page of product -  18\n",
      "scraping  1870  review page of product -  18\n",
      "scraping  1880  review page of product -  18\n",
      "scraping  1890  review page of product -  18\n",
      "scraping  1900  review page of product -  18\n",
      "scraping  1910  review page of product -  18\n",
      "scraping  1920  review page of product -  18\n",
      "scraping  1930  review page of product -  18\n",
      "scraping  1940  review page of product -  18\n",
      "scraping  1950  review page of product -  18\n",
      "scraping reviews of product -  19\n",
      "scraping  1960  review page of product -  19\n",
      "scraping  1970  review page of product -  19\n",
      "scraping  1980  review page of product -  19\n",
      "scraping  1990  review page of product -  19\n",
      "scraping  2000  review page of product -  19\n",
      "scraping  2010  review page of product -  19\n",
      "scraping  2020  review page of product -  19\n",
      "scraping  2030  review page of product -  19\n",
      "scraping  2040  review page of product -  19\n",
      "scraping  2050  review page of product -  19\n",
      "scraping  2060  review page of product -  19\n",
      "scraping  2070  review page of product -  19\n",
      "scraping  2080  review page of product -  19\n",
      "scraping  2090  review page of product -  19\n",
      "scraping reviews of product -  20\n",
      "scraping  2100  review page of product -  20\n",
      "scraping  2110  review page of product -  20\n",
      "scraping  2120  review page of product -  20\n",
      "scraping  2130  review page of product -  20\n",
      "scraping  2140  review page of product -  20\n",
      "scraping  2150  review page of product -  20\n",
      "scraping  2160  review page of product -  20\n",
      "scraping  2170  review page of product -  20\n",
      "scraping  2180  review page of product -  20\n",
      "scraping  2190  review page of product -  20\n",
      "scraping  2200  review page of product -  20\n",
      "scraping  2210  review page of product -  20\n",
      "scraping  2220  review page of product -  20\n",
      "scraping  2230  review page of product -  20\n",
      "scraping reviews of product -  21\n",
      "scraping  2240  review page of product -  21\n",
      "scraping  2250  review page of product -  21\n",
      "scraping  2260  review page of product -  21\n",
      "scraping  2270  review page of product -  21\n",
      "scraping  2280  review page of product -  21\n",
      "scraping  2290  review page of product -  21\n",
      "scraping  2300  review page of product -  21\n",
      "scraping  2310  review page of product -  21\n",
      "scraping  2320  review page of product -  21\n",
      "scraping  2330  review page of product -  21\n",
      "scraping  2340  review page of product -  21\n",
      "scraping  2350  review page of product -  21\n",
      "scraping  2360  review page of product -  21\n",
      "scraping  2370  review page of product -  21\n",
      "scraping reviews of product -  22\n",
      "scraping  2380  review page of product -  22\n",
      "scraping  2390  review page of product -  22\n",
      "scraping  2400  review page of product -  22\n",
      "scraping  2410  review page of product -  22\n",
      "scraping  2420  review page of product -  22\n",
      "scraping  2430  review page of product -  22\n",
      "scraping  2440  review page of product -  22\n",
      "scraping  2450  review page of product -  22\n",
      "scraping  2460  review page of product -  22\n",
      "scraping  2470  review page of product -  22\n",
      "scraping  2480  review page of product -  22\n",
      "scraping  2490  review page of product -  22\n",
      "scraping  2500  review page of product -  22\n",
      "scraping  2510  review page of product -  22\n",
      "scraping reviews of product -  23\n",
      "scraping  2520  review page of product -  23\n",
      "scraping  2530  review page of product -  23\n",
      "scraping  2540  review page of product -  23\n",
      "scraping  2550  review page of product -  23\n",
      "scraping  2560  review page of product -  23\n",
      "scraping  2570  review page of product -  23\n",
      "scraping  2580  review page of product -  23\n",
      "scraping  2590  review page of product -  23\n",
      "scraping  2600  review page of product -  23\n",
      "scraping  2610  review page of product -  23\n",
      "scraping  2620  review page of product -  23\n",
      "scraping  2630  review page of product -  23\n",
      "scraping  2640  review page of product -  23\n",
      "scraping  2650  review page of product -  23\n",
      "scraping reviews of product -  24\n",
      "scraping  2660  review page of product -  24\n",
      "scraping  2670  review page of product -  24\n",
      "scraping  2680  review page of product -  24\n",
      "scraping  2690  review page of product -  24\n",
      "scraping  2700  review page of product -  24\n",
      "scraping  2710  review page of product -  24\n",
      "scraping  2720  review page of product -  24\n",
      "scraping  2730  review page of product -  24\n",
      "scraping  2740  review page of product -  24\n",
      "scraping  2750  review page of product -  24\n",
      "scraping  2760  review page of product -  24\n",
      "scraping  2770  review page of product -  24\n",
      "scraping  2780  review page of product -  24\n",
      "scraping  2790  review page of product -  24\n",
      "scraping reviews of product -  25\n",
      "scraping  2800  review page of product -  25\n",
      "scraping  2810  review page of product -  25\n",
      "scraping  2820  review page of product -  25\n",
      "scraping  2830  review page of product -  25\n",
      "scraping  2840  review page of product -  25\n",
      "scraping  2850  review page of product -  25\n",
      "scraping  2860  review page of product -  25\n",
      "scraping  2870  review page of product -  25\n",
      "scraping  2880  review page of product -  25\n",
      "scraping  2890  review page of product -  25\n",
      "scraping  2900  review page of product -  25\n",
      "scraping  2910  review page of product -  25\n",
      "scraping  2920  review page of product -  25\n",
      "scraping  2930  review page of product -  25\n",
      "scraping reviews of product -  26\n",
      "scraping  2940  review page of product -  26\n",
      "scraping  2950  review page of product -  26\n",
      "scraping  2960  review page of product -  26\n",
      "scraping  2970  review page of product -  26\n",
      "scraping  2980  review page of product -  26\n",
      "scraping  2990  review page of product -  26\n",
      "scraping  3000  review page of product -  26\n",
      "scraping  3010  review page of product -  26\n",
      "scraping  3020  review page of product -  26\n",
      "scraping  3030  review page of product -  26\n",
      "scraping  3040  review page of product -  26\n",
      "scraping  3050  review page of product -  26\n",
      "scraping  3060  review page of product -  26\n",
      "scraping  3070  review page of product -  26\n",
      "scraping reviews of product -  27\n",
      "scraping  3080  review page of product -  27\n",
      "scraping  3090  review page of product -  27\n",
      "scraping  3100  review page of product -  27\n",
      "scraping  3110  review page of product -  27\n",
      "scraping  3120  review page of product -  27\n",
      "scraping  3130  review page of product -  27\n",
      "scraping  3140  review page of product -  27\n",
      "scraping  3150  review page of product -  27\n",
      "scraping  3160  review page of product -  27\n",
      "scraping  3170  review page of product -  27\n",
      "scraping  3180  review page of product -  27\n",
      "scraping  3190  review page of product -  27\n",
      "scraping  3200  review page of product -  27\n",
      "scraping  3210  review page of product -  27\n",
      "scraping reviews of product -  28\n",
      "scraping  3220  review page of product -  28\n",
      "scraping  3230  review page of product -  28\n",
      "scraping  3240  review page of product -  28\n",
      "scraping  3250  review page of product -  28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping  3260  review page of product -  28\n",
      "scraping  3270  review page of product -  28\n",
      "scraping  3280  review page of product -  28\n",
      "scraping  3290  review page of product -  28\n",
      "scraping  3300  review page of product -  28\n",
      "scraping  3310  review page of product -  28\n",
      "scraping  3320  review page of product -  28\n",
      "scraping  3330  review page of product -  28\n",
      "scraping  3340  review page of product -  28\n",
      "scraping  3350  review page of product -  28\n",
      "scraping reviews of product -  29\n",
      "scraping reviews of product -  30\n",
      "scraping  3360  review page of product -  30\n",
      "scraping  3370  review page of product -  30\n",
      "scraping  3380  review page of product -  30\n",
      "scraping  3390  review page of product -  30\n",
      "scraping  3400  review page of product -  30\n",
      "scraping  3410  review page of product -  30\n",
      "scraping  3420  review page of product -  30\n",
      "scraping  3430  review page of product -  30\n",
      "scraping  3440  review page of product -  30\n",
      "scraping  3450  review page of product -  30\n",
      "scraping  3460  review page of product -  30\n",
      "scraping  3470  review page of product -  30\n",
      "scraping  3480  review page of product -  30\n",
      "scraping  3490  review page of product -  30\n",
      "scraping reviews of product -  31\n",
      "scraping reviews of product -  32\n",
      "scraping  3500  review page of product -  32\n",
      "scraping  3510  review page of product -  32\n",
      "scraping  3520  review page of product -  32\n",
      "scraping  3530  review page of product -  32\n",
      "scraping  3540  review page of product -  32\n",
      "scraping  3550  review page of product -  32\n",
      "scraping  3560  review page of product -  32\n",
      "scraping  3570  review page of product -  32\n",
      "scraping  3580  review page of product -  32\n",
      "scraping  3590  review page of product -  32\n",
      "scraping  3600  review page of product -  32\n",
      "scraping  3610  review page of product -  32\n",
      "scraping  3620  review page of product -  32\n",
      "scraping  3630  review page of product -  32\n",
      "scraping reviews of product -  33\n",
      "scraping  3640  review page of product -  33\n",
      "scraping  3650  review page of product -  33\n",
      "scraping  3660  review page of product -  33\n",
      "scraping  3670  review page of product -  33\n",
      "scraping  3680  review page of product -  33\n",
      "scraping  3690  review page of product -  33\n",
      "scraping  3700  review page of product -  33\n",
      "scraping  3710  review page of product -  33\n",
      "scraping  3720  review page of product -  33\n",
      "scraping  3730  review page of product -  33\n",
      "scraping  3740  review page of product -  33\n",
      "scraping  3750  review page of product -  33\n",
      "scraping  3760  review page of product -  33\n",
      "scraping  3770  review page of product -  33\n",
      "scraping reviews of product -  34\n",
      "scraping  3780  review page of product -  34\n",
      "scraping  3790  review page of product -  34\n",
      "scraping  3800  review page of product -  34\n",
      "scraping  3810  review page of product -  34\n",
      "scraping  3820  review page of product -  34\n",
      "scraping  3830  review page of product -  34\n",
      "scraping  3840  review page of product -  34\n",
      "scraping  3850  review page of product -  34\n",
      "scraping  3860  review page of product -  34\n",
      "scraping  3870  review page of product -  34\n",
      "scraping  3880  review page of product -  34\n",
      "scraping  3890  review page of product -  34\n",
      "scraping  3900  review page of product -  34\n",
      "scraping  3910  review page of product -  34\n",
      "scraping reviews of product -  35\n",
      "scraping  3920  review page of product -  35\n",
      "scraping  3930  review page of product -  35\n",
      "scraping  3940  review page of product -  35\n",
      "scraping  3950  review page of product -  35\n",
      "scraping  3960  review page of product -  35\n",
      "scraping  3970  review page of product -  35\n",
      "scraping  3980  review page of product -  35\n",
      "scraping  3990  review page of product -  35\n",
      "scraping  4000  review page of product -  35\n",
      "scraping  4010  review page of product -  35\n",
      "scraping  4020  review page of product -  35\n",
      "scraping  4030  review page of product -  35\n",
      "scraping  4040  review page of product -  35\n",
      "scraping  4050  review page of product -  35\n",
      "scraping reviews of product -  36\n",
      "scraping  4060  review page of product -  36\n",
      "scraping  4070  review page of product -  36\n",
      "scraping  4080  review page of product -  36\n",
      "scraping  4090  review page of product -  36\n",
      "scraping  4100  review page of product -  36\n",
      "scraping  4110  review page of product -  36\n",
      "scraping  4120  review page of product -  36\n",
      "scraping  4130  review page of product -  36\n",
      "scraping  4140  review page of product -  36\n",
      "scraping  4150  review page of product -  36\n",
      "scraping  4160  review page of product -  36\n",
      "scraping  4170  review page of product -  36\n",
      "scraping  4180  review page of product -  36\n",
      "scraping  4190  review page of product -  36\n",
      "scraping reviews of product -  37\n",
      "scraping  4200  review page of product -  37\n",
      "scraping  4210  review page of product -  37\n",
      "scraping  4220  review page of product -  37\n",
      "scraping  4230  review page of product -  37\n",
      "scraping  4240  review page of product -  37\n",
      "scraping  4250  review page of product -  37\n",
      "scraping  4260  review page of product -  37\n",
      "scraping  4270  review page of product -  37\n",
      "scraping  4280  review page of product -  37\n",
      "scraping  4290  review page of product -  37\n",
      "scraping  4300  review page of product -  37\n",
      "scraping  4310  review page of product -  37\n",
      "scraping  4320  review page of product -  37\n",
      "scraping  4330  review page of product -  37\n",
      "scraping reviews of product -  38\n",
      "scraping  4340  review page of product -  38\n",
      "scraping  4350  review page of product -  38\n",
      "scraping  4360  review page of product -  38\n",
      "scraping  4370  review page of product -  38\n",
      "scraping  4380  review page of product -  38\n",
      "scraping  4390  review page of product -  38\n",
      "scraping  4400  review page of product -  38\n",
      "scraping  4410  review page of product -  38\n",
      "scraping  4420  review page of product -  38\n",
      "scraping  4430  review page of product -  38\n",
      "scraping  4440  review page of product -  38\n",
      "scraping  4450  review page of product -  38\n",
      "scraping  4460  review page of product -  38\n",
      "scraping  4470  review page of product -  38\n",
      "scraping reviews of product -  39\n",
      "scraping  4480  review page of product -  39\n",
      "scraping  4490  review page of product -  39\n",
      "scraping  4500  review page of product -  39\n",
      "scraping  4510  review page of product -  39\n",
      "scraping  4520  review page of product -  39\n",
      "scraping  4530  review page of product -  39\n",
      "scraping  4540  review page of product -  39\n",
      "scraping  4550  review page of product -  39\n",
      "scraping  4560  review page of product -  39\n",
      "scraping  4570  review page of product -  39\n",
      "scraping  4580  review page of product -  39\n",
      "scraping  4590  review page of product -  39\n",
      "scraping  4600  review page of product -  39\n",
      "scraping  4610  review page of product -  39\n",
      "scraping reviews of product -  40\n",
      "scraping  4620  review page of product -  40\n",
      "scraping  4630  review page of product -  40\n",
      "scraping  4640  review page of product -  40\n",
      "scraping  4640  review page of product -  40\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-35832c767de3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://localhost:8000/render.html'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wait'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"<Response [503]>\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#####amazon is blocking you######'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no of pages scraped - '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "def clean_title(item):\n",
    "    if item == None:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return item.text.strip().replace('\\n', '')\n",
    "    \n",
    "def clean_rating(item):\n",
    "    if item == None:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(item.text[:3])\n",
    "\n",
    "def clean_body(item):\n",
    "    if item == None:\n",
    "        print(\"empty body\")\n",
    "        return \"\"\n",
    "    else:\n",
    "        return item.text.strip()\n",
    "#df = pd.DataFrame(columns = ['product', 'review_title', 'review_rating', 'review_text'])\n",
    "df = pd.read_csv('scraped_data.csv')\n",
    "\n",
    "\n",
    "#first 450 should be scraped again\n",
    "products = pd.read_csv('products_complete.csv')\n",
    "i = len(df)\n",
    "\n",
    "for prd_idx in range(39, len(products)):\n",
    "    print('scraping reviews of product - ', prd_idx + 1)\n",
    "    url_base = products['review_pages'][prd_idx]\n",
    "    \n",
    "    if url_base == \"\":\n",
    "        continue\n",
    "    if type(url_base) == type(2.0):\n",
    "        continue\n",
    "    \n",
    "    for page in range(1,15):\n",
    "        print('scraping ', i, ' review page of product - ', prd_idx + 1)\n",
    "        url = 'https://amazon.com' + url_base + str(page)\n",
    "        r = requests.get('http://localhost:8000/render.html', {'url': url, 'wait': random.randint(2,20)})\n",
    "        \n",
    "        if str(r) == \"<Response [503]>\" or string in soup.find('body').text:\n",
    "            print('#####amazon is blocking you######')\n",
    "            print('no of pages scraped - ',i )\n",
    "            break\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        #check if we have reached last page\n",
    "        if soup.find('li', {'class': 'a-disabled a-last'}):\n",
    "            break\n",
    "\n",
    "        reviews = soup.find_all('div', {'data-hook': 'review'})\n",
    "\n",
    "        for items in reviews:\n",
    "            product = soup.title.text.replace('Amazon.com: Customer reviews:', '').strip()\n",
    "            reviews_title= clean_title(items.find('a', {'data-hook': 'review-title'}))\n",
    "            review_rating= clean_rating(items.find('i', {'data-hook': 'review-star-rating'}))\n",
    "            reviews_text= clean_body(items.find('span', {'data-hook': 'review-body'}))\n",
    "            df.loc[i] = [product, reviews_title, review_rating, reviews_text]\n",
    "            i = i + 1\n",
    "\n",
    "print(\"Done scraping\")        \n",
    "df.to_csv('scraped_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6de8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scraped_data1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
